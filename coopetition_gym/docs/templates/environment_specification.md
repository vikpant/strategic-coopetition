# Environment Documentation Templates

This document provides standardized templates for documenting Coopetition-Gym environments according to modern MARL research conventions.

---

## MARL Classification Block

Insert this block after the Overview section in each environment document.

```markdown
## MARL Classification

| Property | Value |
|----------|-------|
| **Game Type** | Markov Game / Dec-POMDP / Mean-Field Game |
| **Cooperation Structure** | Competitive / Cooperative / Mixed-Motive |
| **Observability** | Full / Partial (specify hidden components) |
| **Communication** | None / Implicit (actions) / Explicit (messages) |
| **Agent Symmetry** | Symmetric / Asymmetric (specify differences) |
| **Reward Structure** | Individual / Team / Mixed (interdependence) |
| **Action Space** | Continuous / Discrete (specify bounds) |
| **State Dynamics** | Deterministic / Stochastic |
| **Horizon** | Finite (T=N) / Infinite (discounted) |
| **Canonical Comparison** | Reference to similar benchmarks |
```

---

## Formal Specification Block

Insert this block after the MARL Classification section.

```markdown
## Formal Specification

This environment is formalized as an N-player Markov Game M = (N, S, {A_i}, P, {R_i}, Î³, T).

### Agents
N = {1, ..., n} with n = [number of agents]

### State Space
S âŠ† â„^d where d = [dimension formula]

Components:
- **Actions**: a âˆˆ â„^N (previous cooperation levels)
- **Trust Matrix**: Ï„ âˆˆ [0,1]^(NÃ—N) (pairwise trust)
- **Reputation Matrix**: R âˆˆ [0,1]^(NÃ—N) (reputation damage)
- **Interdependence**: D âˆˆ [0,1]^(NÃ—N) (structural dependencies)
- **Time**: t âˆˆ [0,1] (normalized timestep)

### Action Space
A_i = [0, e_i] âŠ‚ â„ for agent i with endowment e_i

### Transition Dynamics
**Trust Update**:
Ï„_ij(t+1) = clip(Ï„_ij(t) + Î”Ï„_ij, 0, Î˜_ij)

where:
- Î”Ï„_ij = Î»âº Â· max(0, Ïƒ_ij) Â· (1 - Ï„_ij) - Î»â» Â· max(0, -Ïƒ_ij) Â· Ï„_ij
- Ïƒ_ij = Îº Â· (a_j - b_j) / b_j (cooperation signal)
- Î˜_ij = 1 - R_ij (trust ceiling from reputation)

**Reputation Update**:
R_ij(t+1) = clip(R_ij(t) Â· (1 - Î´_R) + Î¼_R Â· ğŸ™[Ïƒ_ij < 0], 0, 1)

### Reward Function
r_i(s, a) = U_i(a) where integrated utility is:

U_i = (e_i - a_i) + f(a_i) + Î±_i Â· G(a) + Î£_j D_ij Â· Ï€_j

with:
- f(a_i) = Î¸ Â· ln(1 + a_i) (individual value)
- G(a) = (âˆ_i a_i)^(1/N) Â· (1 + Î³ Â· C(a)) (synergy)
- C(a) = min_i(a_i / e_i) (complementarity)

### Episode Termination
- **Truncation**: t â‰¥ T (max_steps reached)
- **Termination**: [environment-specific conditions]

### Discount Factor
Î³ = 1.0 (finite horizon, undiscounted episodic)
```

---

## Parameter Table Template

```markdown
### Environment Parameters

| Parameter | Symbol | Default | Range | Description |
|-----------|--------|---------|-------|-------------|
| Max Steps | T | 100 | [50, 500] | Episode horizon |
| Trust Building Rate | Î»âº | 0.10 | [0.05, 0.20] | Cooperation â†’ trust |
| Trust Erosion Rate | Î»â» | 0.30 | [0.20, 0.50] | Defection â†’ trust loss |
| ... | ... | ... | ... | ... |
```

---

## Observation Space Table Template

```markdown
### Observation Space Details

| Component | Indices | Shape | Range | Description |
|-----------|---------|-------|-------|-------------|
| Actions | [0:N] | (N,) | [0, e_max] | Previous cooperation levels |
| Trust Matrix | [N:N+NÂ²] | (N,N) | [0, 1] | Pairwise trust Ï„_ij |
| Reputation Matrix | [N+NÂ²:N+2NÂ²] | (N,N) | [0, 1] | Reputation damage R_ij |
| Interdependence | [N+2NÂ²:N+3NÂ²] | (N,N) | [0, 1] | Structural dependencies D_ij |
| Timestep | [N+3NÂ²] | (1,) | [0, 1] | Normalized t/T |

**Total Dimension**: d = N + 3NÂ² + 1
```
